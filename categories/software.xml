<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>I Love Symposia! (Posts about software)</title><link>https://ilovesymposia.com/</link><description></description><atom:link href="https://ilovesymposia.com/categories/software.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2019 &lt;a href="mailto:jni.soma@fastmail.com"&gt;Juan Nunez-Iglesias&lt;/a&gt; 
&lt;a rel="license" href="https://creativecommons.org/licenses/by/4.0/"&gt;
&lt;img alt="Creative Commons License BY"
style="border-width:0; margin-bottom:12px;"
src="https://i.creativecommons.org/l/by/4.0/88x31.png"&gt;&lt;/a&gt;</copyright><lastBuildDate>Fri, 25 Oct 2019 04:33:45 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Introducing napari: a fast n-dimensional image viewer in Python</title><link>https://ilovesymposia.com/2019/10/24/introducing-napari-a-fast-n-dimensional-image-viewer-in-python/</link><dc:creator>Juan Nunez-Iglesias</dc:creator><description>&lt;div&gt;&lt;p&gt;I'm really excited to finally, officially, share a new(ish) project called
napari with the world.
We have been developing napari &lt;a href="https://github.com/napari/napari"&gt;in the open&lt;/a&gt;
from the very first commit, but we didn't want to make any premature fanfare
about it… Until now. It's still alpha software, but for months now, both the
core napari team and a few collaborators/early adopters have been using napari
in our daily work. I've found it life-changing.&lt;/p&gt;
&lt;h2&gt;The background&lt;/h2&gt;
&lt;p&gt;I've been looking for a great nD volume viewer in Python for the better part of
a decade. In 2009, I joined Mitya Chklovskii's lab and the FlyEM team at the
Janelia [Farm] Research Campus to work on the segmentation of 3D electron
microscopy (EM) volumes. I started out in Matlab, but moved to Python pretty
quickly and it was a very smooth transition (highly recommended! ;). Looking at
my data was always annoying though. I was either looking at single 2D slices
using &lt;code&gt;matplotlib.pyplot.imshow&lt;/code&gt;, or saving the volumes in VTK format and
loading them into ITK-SNAP — which worked ok but required me to constantly be
changing terminals, and anyway was pretty inefficient because my disk ended up
cluttered with “temporary” VTK volumes.&lt;/p&gt;
&lt;p&gt;I tried a bunch of things after that time, including Mayavi and even building my
own orthogonal views viewer with Matplotlib (which was super slow), but nothing
really clicked. What's worse, I didn't see any movement on this — I even found
a very discouraging thread on MNE-Python in which Gaël Varoquaux concluded,
given the lack of support, that 3D visualisation was not mission critical to
anyone and not worth pursuing further. (!) Throughout that time, I kept living
with either manually picking out 2D slices, or going back to tools outside of
Python, with all the context switching that entailed. The end result is
that I was looking at my data far less than I should have been, which slowed
down my work. I can't count the number of silly mistakes I made and dead ends I
chased, just because I wasn't looking at the data enough.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;h2&gt;The beginning&lt;/h2&gt;
&lt;p&gt;In the meantime though, I was busy improving support for n-dimensional images
in scikit-image. In May last year, Nelle Varoquaux organised a joint sprint with
developers from scikit-learn, scikit-image, and dask at UC Berkeley, and I was
one of the lucky invitees. I'd recently seen that Loïc Royer, a good friend
from my Janelia days, had moved to San Francisco to start his lab at the Chan
Zuckerberg Biohub, so I asked him if I could crash at his place for a few days
before the sprint.&lt;/p&gt;
&lt;p&gt;I knew Loïc as a Java guy. In Janelia he'd repeatedly extolled the virtues of
Java to me, and since then he'd worked on some incredible Java software,
including ClearVolume, a super-fast 3D viewer, and ClearControl, a super-fast
microscope control library (you might detect a theme there ;).  In fact,
although I love Python and its ecosystem and what we've built with
scikit-image, I've always been intimidated by Fiji and its ecosystem and its
&lt;del&gt;10,000&lt;/del&gt; 15,000 citations. Was I deluding myself that Python was important in
biology?&lt;/p&gt;
&lt;p&gt;So I was both shocked and delighted when Loïc casually mentioned that he needed
a fast nD viewer in Python, and that we should build it together. Loïc had been
pushing the state of the art of deep learning in microscopy (and continues to
do so), and, despite the hard work of many to integrate Fiji with the major
deep learning learning libraries (which are Python), as well as the wider
scientific Python ecosystem, it remains challenging to use both together. It
might well remain so, because the build, installation, and dependency tooling
is so disparate between the two communities.  And so that evening, in Loïc's
apartment, napari (lowercase n) was born (though it did not yet have a name).&lt;/p&gt;
&lt;figure&gt;
  &lt;img src="https://ilovesymposia.com/napari/loic-walking-sf.jpg" alt="Loïc walking SF" style="width:100%"&gt;
  &lt;figcaption&gt;&lt;em&gt;Loïc walking around San Francisco the weekend after I landed.&lt;/em&gt;&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Following on from his work on ClearVolume, Loïc and I agreed on some founding
design principles for our tool:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;n-dimensional first;&lt;/li&gt;
&lt;li&gt;native (neither of us likes opening a browser to work);&lt;/li&gt;
&lt;li&gt;blazing fast (GPU-powered);&lt;/li&gt;
&lt;li&gt;native 2D and 3D viewing; and&lt;/li&gt;
&lt;li&gt;minimal new windows and pop-ups, choosing layering instead.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In terms of speed, we knew it was doable, thanks to Martin Weigert's excellent
3D volume viewer, &lt;a href="https://github.com/maweigert/spimagine"&gt;spimagine&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The next week, at the Berkeley sprint, I finally met Kira Evans, a contributor
to scikit-image who had made several incredibly technical pull requests, on my
favourite topic of extending n-dimensional support, and whom I'd thus asked
Nelle to invite to the sprint. She had turned out to be a freshman at
Northeastern University, but despite her age she was already doing great things
in open source. In general, life is a big accumulation of small decisions you
don't even think about. On certain rare occasions, though, you make decisions
on which you look back and think, hot damn that was a good decision! Inviting
Kira is one of those for me. (Nelle agreed.)&lt;/p&gt;
&lt;figure&gt;
  &lt;img src="https://ilovesymposia.com/napari/kira-john-emma-me-dask.jpg" alt="John explains dask-image" style="width:100%"&gt;
  &lt;figcaption&gt;&lt;em&gt;John Kirkham explains dask-image to Kira, Emmanuelle Gouillart, and me at the Berkeley sprint.&lt;/em&gt;&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;That week at the sprint, Loïc was able to hack out a quick prototype.
Meanwhile, Kira was busy helping scikit-image with n-dimensional rotations,
LowLevelCallables in C and Cython, and various other crazy things.&lt;/p&gt;
&lt;p&gt;I'll take a short moment to acknowledge &lt;a href="http://vispy.org"&gt;VisPy&lt;/a&gt;, which is the
basis for all of napari's visualisation: napari's canvas is a VisPy canvas, its
events are VisPy events, and its visual building blocks are VisPy Visuals. I
don't know the history of VisPy, but I want to thank all its
&lt;a href="https://github.com/vispy/vispy/graphs/contributors"&gt;contributors&lt;/a&gt;, especially
Almar Klein, who drove it for a very long time, and David Hoese, who
resurrected it when Almar could no longer maintain it, and who maintains
it today. VisPy is yet another example of open source software being
&lt;a href="https://ilovesymposia.com/2019/05/28/why-citations-are-not-enough-for-open-source-software/"&gt;inadequately supported by academia&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The next weekend, on the Caltrain to the &lt;a href="https://computerhistory.org/"&gt;Computing History
Museum&lt;/a&gt;, we worked on choosing a name.
After playing around with some terrible acronyms, we
decided to continue the theme of Pacific islands begun by Fiji (though
Fiji itself is a spectacular recursive acronym, “Fiji Is Just ImageJ”).
We needed a starting point, and we settled on the
geographic midpoint between Loïc's base of San Francisco and mine of Melbourne.
That's in the middle of the ocean, of course, but not too far from
the tiny village of Napari, in the Republic of Kiribati. We
thought it had a nice ring to it, and the name stuck.&lt;/p&gt;
&lt;p&gt;There was a big risk of napari never getting off the ground. Starting a new lab
is hard work, and Loïc
knew he would not have time to develop it further. He did, however, have some
funds available for a summer intern, and after seeing the work Kira did that
week, he offered her the internship. (As a result, Kira is now officially a
college dropout and full-time software engineer at CZI, the Chan Zuckerberg
Initiative.) That summer, under the guidance of Loïc, Stéfan van der Walt, and
myself, Kira put together the first implementation of napari as you see it
today.&lt;/p&gt;
&lt;p&gt;By late summer/early fall, although internally napari was quite a mess, as
tends to happen in new, fast-growing projects, functionally it was already
impressive enough that Jeremy Freeman and Nick Sofroniew, from CZI's
Computational Biology division, started paying close attention. Nick, who'd
had similar experiences to mine working with Python and nD images, fell in
love with it, and literally could not wait for us to move it forward. He took
matters into his own hands.&lt;/p&gt;
&lt;p&gt;Initially, Nick brought some brilliant management to napari, instituting weekly
meetings that he drove (and continues to drive) like a champion. Those meetings
were critical to bringing others into the loop, including Ahmet Can Solak, Kevin
Yamauchi, Bryant Chunn, and Shannon Axelrod, who started to make pull requests
to improve napari.  Pretty soon, though, Nick made his own pull request, and
after that it was like seeing a racecar take off.  No one has done more for
napari than Nick, and Loïc and I owe him an enormous debt of gratitude.&lt;/p&gt;
&lt;p&gt;Soon after that, the &lt;a href="https://github.com/spacetx/starfish"&gt;StarFISH team&lt;/a&gt; at
CZI adopted napari as their main image viewer, which again helped us
discover bugs, improve our UI, and add features. By February, everyone in the
project was using it regularly, despite its warts. We started to think about
broadening the group of people with eyes on napari.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src="https://ilovesymposia.com/napari/nick-neurodegen-meeting.jpg" alt="Nick demoing napari" style="width:100%"&gt;
  &lt;figcaption&gt;&lt;em&gt;Nick shows napari to attendees of the &lt;a href="https://medium.com/@cziscience/building-a-scientific-community-that-is-more-than-the-sum-of-its-parts-ffc0171617a5"&gt;Neurodegeneration Challenge Network Investigators Meeting&lt;/a&gt; in Februrary. &lt;a href="https://twitter.com/cziscience/status/1101005066599723009"&gt;Photo by CZI Science.&lt;/a&gt;&lt;/em&gt;&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;CZI was organising a meeting for grantees of its &lt;a href="https://go.chanzuckerberg.com/imaging"&gt;Imaging
Scientists&lt;/a&gt; and &lt;a href="https://go.chanzuckerberg.com/imaging#imaging-software-fellows"&gt;Imaging Software
Fellows&lt;/a&gt;
programs in March, which we thought would be a good opportunity to grow the
team. Among others, we invited John Kirkham (NVIDIA) and Eric Perlman (then at
Johns Hopkins, now freelancing). The CZI meeting was a dramatic demonstration of the power of
bringing together people with complementary experience, as John added support
for viewing bigger-than-RAM &lt;a href="https://docs.dask.org/en/stable/array.html"&gt;dask
arrays&lt;/a&gt; in about 20 minutes flat,
and Eric massively improved the performance of our segmentation visualisation
layer.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src="https://ilovesymposia.com/napari/loic-napari-master-class.jpg" alt="Loïc explains napari" style="width:100%"&gt;
  &lt;figcaption&gt;&lt;em&gt;Loïc explaining napari's design to John Kirkham and Wei Ouyang at the Chan Zuckerberg Biohub the day after the CZI meeting.&lt;/em&gt;&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;I came out of the March meeting thinking hey, this napari thing might have legs!
Not only had newcomers been able to improve it quickly without knowing
the codebase (which usually points to at least &lt;em&gt;decent&lt;/em&gt; design), but we heard
over and over from the imaging scientists that viewing and annotating large
datasets remained a challenge for them.&lt;/p&gt;
&lt;p&gt;So, we started gently expanding the user base, but in hushed tones, full of
caveats: “This software we're working on might be useful for you… If you're
brave and can work around all the missing functionality… Be sure to report any
issues…” One of our most frequent requests, which was indeed part of the napari
plan from the very beginning, was 3D volume rendering, and Pranathi Vemuri, a
data scientist at the Biohub, implemented that just in time for SciPy 2019. At
that conference, Nick presented napari to the public for the first time,
because many SciPy attendees tend to not mind working with development versions
of libraries. Indeed, we got contributions that week from Alex de Siqueira
(from the scikit-image team) and Matthias Bussonnier (IPython).&lt;/p&gt;
&lt;p&gt;The biggest revelation for me, though, came immediately after SciPy, when I
went to Jackson Lab to teach a workshop on scikit-image. I've taught
scikit-image many times before, but for the first time, I went off-script and
analysed new data live, on IPython, rather than using Jupyter notebooks
pre-populated with toy data. I used napari instead of matplotlib, and found
napari's layers model &lt;em&gt;insanely&lt;/em&gt; useful to visualise every step of the
analysis, one on top of the other, toggling their visibility on and off to
compare them. And it was super easy to add interactivity to the mix, clicking
on some points in napari, then grabbing those points to use as watershed seeds,
and popping the resulting segmentation as another layer to napari.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src="https://ilovesymposia.com/napari/napari-annotated-coins.png" alt="Annotated Coins" style="width:100%"&gt;
  &lt;figcaption&gt;&lt;em&gt;Combining interactive annotation and segmentation algorithms with napari.&lt;/em&gt;&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;In the months since then, we've spent a lot of time improving the code, and
polishing the little edge cases, like making sure the coordinates reported by
the cursor are pixel perfect, merging the previously separate Image (2D) and
Volume (3D) layers, and extending 3D and multi-resolution support to all
layers.&lt;/p&gt;
&lt;p&gt;Thanks to CZI's massive in-house investment in open source, we also actually
got an &lt;a href="https://github.com/napari/napari/issues/469"&gt;audit&lt;/a&gt; for napari's GUI
from Lia Prins, a UX designer at CZI — an incredible opportunity that few
academic projects get. And, to repeat a familiar pattern, Nick immediately got
to work and implemented a bunch of fixes from the audit. To me, this update is
what's most pushed me to write this post, as the UI now feels more like a
coherent whole than the mishmash of features that results from organic growth
of a project.&lt;/p&gt;
&lt;h2&gt;napari now&lt;/h2&gt;
&lt;p&gt;As I mentioned at the start, currently, everyone on the team uses napari on a
daily basis for their own work. Our workflows actually look quite
different, yet napari meets the needs of all of them, in some form or another.
Last month we were surprised to find that Constantin Pape, at EMBL, was
developing his own viewer, Heimdall, on top of napari, completely independently
from us. I'm a big fan of Constantin's work, so little has brought me more joy
than finding his &lt;a href="https://github.com/constantinpape/heimdall"&gt;repo&lt;/a&gt; and reading
this comment:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;most of the credit goes to napari; it's so great to finally have a decent
python viewer.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So, what are those use cases?&lt;/p&gt;
&lt;h3&gt;1. Just &lt;em&gt;looking&lt;/em&gt; at NumPy ndarrays quickly&lt;/h3&gt;
&lt;p&gt;This is my most common use case. I like to think about and use 2D, 3D, and 4D
images interchangeably. So, I often find myself calling &lt;code&gt;plt.imshow&lt;/code&gt; on a 3D
array and being greeted by a &lt;code&gt;TypeError: Invalid dimensions for image data&lt;/code&gt;,
&lt;em&gt;after&lt;/em&gt; the figure window has popped up, which now stares back at me blank and
forlorn. No more, with &lt;code&gt;napari.view_image&lt;/code&gt;. By default, napari will display the
last two dimensions of an array, and put in as many sliders as necessary for
the remaining dimensions.&lt;/p&gt;
&lt;p&gt;To illustrate, I'll create a syntethic 4D array of blobs using scikit-image's
&lt;code&gt;binary_blobs&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;skimage&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;filters&lt;/span&gt;


&lt;span class="n"&gt;blobs_raw&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;binary_blobs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;length&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_dim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;volume_fraction&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="n"&gt;blobs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;filters&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gaussian&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;blobs_raw&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;blobs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;


&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;(10, 256, 256, 256)
&lt;/pre&gt;


&lt;p&gt;Now we can look at the volume in napari:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;viewer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;napari&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;view_image&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;blobs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;


&lt;video width="90%" controls autoplay loop muted playsinline&gt;
  &lt;source src="https://ilovesymposia.com/napari/napari-blobs-720p.mp4" type="video/mp4"&gt;&lt;/source&gt;
  &lt;source src="https://ilovesymposia.com/napari/napari-blobs-720p.ogg" type="video/ogg"&gt;&lt;/source&gt;
  &lt;img src="https://ilovesymposia.com/napari/napari-blobs-720p-frame.jpg" title="Your browser does not support the video tag."&gt;
&lt;/video&gt;

&lt;p&gt;Thanks to VisPy and OpenGL, the canvas is just
blazing fast, and a joy to navigate.&lt;/p&gt;
&lt;p&gt;Using napari, we can immediately see that the blobs grow dramatically along
the leading axis. With my previous matplotlib workflow, I might have missed
that, as I would only look at one or two slices before continuing my workflow
in whatever preconceived direction I'd chosen.&lt;/p&gt;
&lt;p&gt;We can click on the little cube icon to switch to a 3D view (or type
&lt;code&gt;viewer.dims.ndisplay = 3&lt;/code&gt; in our IPython terminal). Napari will remove
one of the sliders, and display a maximum intensity projection of the volume.&lt;/p&gt;
&lt;video width="90%" controls autoplay loop muted playsinline&gt;
  &lt;source src="https://ilovesymposia.com/napari/napari-blobs-3d-720p.mp4" type="video/mp4"&gt;&lt;/source&gt;
  &lt;source src="https://ilovesymposia.com/napari/napari-blobs-3d-720p.ogg" type="video/ogg"&gt;&lt;/source&gt;
  &lt;img src="https://ilovesymposia.com/napari/napari-blobs-3d-720p-frame.jpg" title="Your browser does not support the video tag."&gt;
&lt;/video&gt;

&lt;p&gt;White blobs turn out to not look so great in maximum intensity, so let's look
at the 3D view with the famous
&lt;a href="http://fiji.sc/downloads/Spindly-GFP.zip"&gt;mitosis dataset&lt;/a&gt; from Fiji's sample
data (which I think comes from
&lt;a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2064361/"&gt;this paper&lt;/a&gt; by Griffis,
Stuurman and Vale, but I'm not sure...):&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;skimage&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;io&lt;/span&gt;

&lt;span class="n"&gt;mitosis&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;io&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;imread&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'mitosis.tif'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# make sure your working directory is right&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mitosis&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;


&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;(51, 5, 2, 196, 171)
&lt;/pre&gt;


&lt;p&gt;Those axes are time, z, channels, y, and x (TZCYX).&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;viewer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;napari&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;view_image&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mitosis&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'mitosis'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;


&lt;video width="90%" controls autoplay loop muted playsinline&gt;
  &lt;source src="https://ilovesymposia.com/napari/napari-mitosis-720p.mp4" type="video/mp4"&gt;&lt;/source&gt;
  &lt;source src="https://ilovesymposia.com/napari/napari-mitosis-720p.ogg" type="video/ogg"&gt;&lt;/source&gt;
  &lt;img src="https://ilovesymposia.com/napari/napari-mitosis-720p-frame.jpg" title="Your browser does not support the video tag."&gt;
&lt;/video&gt;

&lt;p&gt;As above, you can see the last two dimensions displayed, then sliders for the
remaining dimensions. The sliders are proportionally sized to the number of
slices along each axis, making it easy to figure out which axis is what. (This
was one of Lia's recommendations that Nick implemented.) (And yes, labeled axes
are in our roadmap!)&lt;/p&gt;
&lt;p&gt;We want to see the two channels as individual images to overlay, rather than as
an extra dimension.  We can do this manually with two &lt;code&gt;add_image&lt;/code&gt; calls, or we
can use the &lt;code&gt;view_multichannel&lt;/code&gt; function to overlay multiple channels on one
another. Finally, we can add a scale keyword argument to account for the
different scales in xy and in z:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;viewer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;napari&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;view_multichannel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;mitosis&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;colormap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'magenta'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'green'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
    &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'aurora-B'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'tubulin'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;scale&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
    &lt;span class="n"&gt;contrast_limits&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;1500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6500&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1600&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16000&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;


&lt;video width="90%" controls autoplay loop muted playsinline&gt;
  &lt;source src="https://ilovesymposia.com/napari/napari-mitosis-3d-720p.mp4" type="video/mp4"&gt;&lt;/source&gt;
  &lt;source src="https://ilovesymposia.com/napari/napari-mitosis-3d-720p.ogg" type="video/ogg"&gt;&lt;/source&gt;
  &lt;img src="https://ilovesymposia.com/napari/napari-mitosis-3d-720p-frame.jpg" title="Your browser does not support the video tag."&gt;
&lt;/video&gt;

&lt;p&gt;The alternate way to do this, which you'll need for more complex workflows, is:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;viewer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;napari&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Viewer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;viewer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_image&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mitosis&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="p"&gt;:],&lt;/span&gt; &lt;span class="n"&gt;colormap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'magenta'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                 &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'aurora-B'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;scale&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                 &lt;span class="n"&gt;contrast_limits&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6500&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;viewer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_image&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mitosis&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="p"&gt;:],&lt;/span&gt; &lt;span class="n"&gt;colormap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'green'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                 &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'tubulin'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;scale&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                 &lt;span class="n"&gt;contrast_limits&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1600&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16000&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;


&lt;h3&gt;2. Overlaying computation results&lt;/h3&gt;
&lt;p&gt;As I mentioned earlier, the first time it really hit me how useful napari could
be was when I was teaching scikit-image at Jackson lab. Napari uses a layered
display model, so you can keep adding layers on top of each other, and change
their opacity or visibility on the fly. This makes it really convenient to
examine the steps of a pipeline as you process data, and maybe try different
methods if the results don't look so great mid-pipeline.&lt;/p&gt;
&lt;p&gt;In this example, I open napari from IPython and I keep adding layers as I try
different segmentation methods on the coins example image from scikit-image:&lt;/p&gt;
&lt;video width="90%" controls autoplay loop muted playsinline&gt;
  &lt;source src="https://ilovesymposia.com/napari/napari-coins-pipeline.mp4" type="video/mp4"&gt;&lt;/source&gt;
  &lt;source src="https://ilovesymposia.com/napari/napari-coins-pipeline.ogg" type="video/ogg"&gt;&lt;/source&gt;
  &lt;img src="https://ilovesymposia.com/napari/napari-coins-pipeline-frame.jpg" title="Your browser does not support the video tag."&gt;
&lt;/video&gt;

&lt;h3&gt;3. Annotating data&lt;/h3&gt;
&lt;p&gt;Sometimes, it can be difficult to get an algorithm to pick out exactly what
you want in an image. With the right UI, however, annotation can be extremely
fast, and just a little interaction can dramatically help automated algorithms.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;skimage&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;skimage&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;filters&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;skimage&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;segmentation&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;skimage&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;morphology&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;napari&lt;/span&gt;


&lt;span class="n"&gt;coins&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coins&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;viewer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;napari&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;view_image&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coins&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'coins'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;edges&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;filters&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sobel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coins&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;edges_layer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;viewer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_image&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;edges&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;colormap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'magenta'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;blending&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'additive'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;pts_layer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;viewer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_points&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;pts_layer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mode&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'add'&lt;/span&gt;
&lt;span class="c1"&gt;# annotate the background and all the coins, in that order&lt;/span&gt;

&lt;span class="n"&gt;coordinates&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pts_layer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;
&lt;span class="n"&gt;coordinates_int&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;round&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coordinates&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;markers_raw&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros_like&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coins&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;markers_raw&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;tuple&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coordinates_int&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coordinates&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="c1"&gt;# raw markers might be in a little watershed "well".&lt;/span&gt;
&lt;span class="n"&gt;markers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;morphology&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dilation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;markers_raw&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;morphology&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;disk&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;segments&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;segmentation&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;watershed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;edges&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;markers&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;labels_layer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;viewer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_labels&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;segments&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# make background 0&lt;/span&gt;
&lt;/pre&gt;


&lt;video width="90%" controls autoplay loop muted playsinline&gt;
  &lt;source src="https://ilovesymposia.com/napari/napari-annotate-coins.mp4" type="video/mp4"&gt;&lt;/source&gt;
  &lt;source src="https://ilovesymposia.com/napari/napari-annotate-coins.ogg" type="video/ogg"&gt;&lt;/source&gt;
  &lt;img src="https://ilovesymposia.com/napari/napari-annotate-coins-frame.jpg" title="Your browser does not support the video tag."&gt;
&lt;/video&gt;

&lt;h3&gt;4. Viewing very large (dask) arrays&lt;/h3&gt;
&lt;p&gt;Thanks to John Kirkham's work, napari only loads the data that
it needs to display. Therefore, virtual arrays such as Dask arrays, HDF5
datasets, and zarr files can be loaded quickly and easily into napari, provided
that the individual slices are small enough.&lt;/p&gt;
&lt;p&gt;Today's microscopes produce datasets ranging in the hundreds of GB to multiple
TB in size. Berkeley's Gokul Upadhyayula has made his lattice light sheet data
publicly available. Nick converted this to a
&lt;a href="https://zarr.readthedocs.io/en/stable/"&gt;zarr file&lt;/a&gt; for ease of access. &lt;/p&gt;
&lt;p&gt;Now, we can use a dask array to view this 100GB array quickly and easily:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;dask&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;da&lt;/span&gt;

&lt;span class="n"&gt;image&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;da&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_zarr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expanduser&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'~/data/gokul-lls/aollsm-m4-560nm.zarr'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;viewer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;napari&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;view_image&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'560nm'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;colormap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'magma'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                           &lt;span class="n"&gt;contrast_limits&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;150&lt;/span&gt;&lt;span class="n"&gt;_000&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;


&lt;video width="90%" controls autoplay loop muted playsinline&gt;
  &lt;source src="https://ilovesymposia.com/napari/napari-gokul-lls.mp4" type="video/mp4"&gt;&lt;/source&gt;
  &lt;source src="https://ilovesymposia.com/napari/napari-gokul-lls.ogg" type="video/ogg"&gt;&lt;/source&gt;
  &lt;img src="https://ilovesymposia.com/napari/napari-gokul-lls-frame.jpg" title="Your browser does not support the video tag."&gt;
&lt;/video&gt;

&lt;h3&gt;5. Quickly looking at images&lt;/h3&gt;
&lt;p&gt;When you &lt;code&gt;pip install napari&lt;/code&gt;, you also get a command-line client that lets
you quickly view image stacks. Here is a
&lt;a href="https://ilovesymposia.com/data/droso-ovarioles-isotropic.tif"&gt;downsampled, isotropic version&lt;/a&gt; of
&lt;a href="https://figshare.com/articles/_/9985568"&gt;this image&lt;/a&gt; from my colleagues,
Volker Hilsenstein and André Nogueira Alves:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="go"&gt;napari ~/data/ovarioles/droso-ovarioles-isotropic.tif&lt;/span&gt;
&lt;/pre&gt;


&lt;video width="90%" controls autoplay loop muted playsinline&gt;
  &lt;source src="https://ilovesymposia.com/napari/napari-ovarioles.mp4" type="video/mp4"&gt;&lt;/source&gt;
  &lt;source src="https://ilovesymposia.com/napari/napari-ovarioles.ogg" type="video/ogg"&gt;&lt;/source&gt;
  &lt;img src="https://ilovesymposia.com/napari/napari-ovarioles-frame.jpg" title="Your browser does not support the video tag."&gt;
&lt;/video&gt;

&lt;p&gt;Or the &lt;a href="https://samples.scif.io/EmbryoCE.zip"&gt;4D C. elegans embryo&lt;/a&gt; from the
&lt;a href="https://scif.io/images/"&gt;scif.io example images&lt;/a&gt; (unzipping gives a folder of
images):&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="go"&gt;napari ~/data/EmbryoCE&lt;/span&gt;
&lt;/pre&gt;


&lt;video width="90%" controls autoplay loop muted playsinline&gt;
  &lt;source src="https://ilovesymposia.com/napari/napari-embryo-ce.mp4" type="video/mp4"&gt;&lt;/source&gt;
  &lt;source src="https://ilovesymposia.com/napari/napari-embryo-ce.ogg" type="video/ogg"&gt;&lt;/source&gt;
  &lt;img src="https://ilovesymposia.com/napari/napari-embryo-ce-frame.jpg" title="Your browser does not support the video tag."&gt;
&lt;/video&gt;

&lt;p&gt;Or a data set of many images, such as the red blood cell spectrin network from
my
&lt;a href="https://peerj.com/articles/4312/"&gt;work with Adam Blanch in Leann Tilley's lab&lt;/a&gt;
(data available from the &lt;a href="https://osf.io"&gt;Open Science Framework&lt;/a&gt;
&lt;a href="http://dx.doi.org/10.17605/OSF.IO/SVPFU"&gt;here&lt;/a&gt;):&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="go"&gt;napari ~/data/schizonts/*.tif&lt;/span&gt;
&lt;/pre&gt;


&lt;video width="90%" controls autoplay loop muted playsinline&gt;
  &lt;source src="https://ilovesymposia.com/napari/napari-schizonts.mp4" type="video/mp4"&gt;&lt;/source&gt;
  &lt;source src="https://ilovesymposia.com/napari/napari-schizonts.ogg" type="video/ogg"&gt;&lt;/source&gt;
  &lt;img src="https://ilovesymposia.com/napari/napari-schizonts-frame.jpg" title="Your browser does not support the video tag."&gt;
&lt;/video&gt;

&lt;h3&gt;6. Parameter sweeps&lt;/h3&gt;
&lt;p&gt;A hat tip to Davis Bennett at Janelia, who
&lt;a href="https://gist.github.com/d-v-b/5dbdb7513d07e3360cbe5c0f3d5cacb6"&gt;came up&lt;/a&gt;
with this one. Suppose you want to manually find the best threshold for an
image. Thanks to dask's lazy evaluation, you can attach a function call to a
dimension slider, and use that slider to call the function with many
different parameter choices. And napari's dimensions model tries to mirror
NumPy's
&lt;a href="https://numpy.org/devdocs/user/theory.broadcasting.html"&gt;broadcasting rules&lt;/a&gt;,
so that you can view data of different dimensionality together.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;skimage&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;dask&lt;/span&gt;


&lt;span class="n"&gt;coins&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coins&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;threshold&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;arr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;da&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;chunks&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;arr&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;

&lt;span class="n"&gt;all_thresholds&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;da&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;threshold&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coins&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;255&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;

&lt;span class="n"&gt;viewer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;napari&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;view_image&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coins&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'coins'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;viewer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_image&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;all_thresholds&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'thresholded'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;colormap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'magenta'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;blending&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'additive'&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;We can even have a bit of fun at the end with 3D rendering... 🙃&lt;/p&gt;
&lt;video width="90%" controls autoplay loop muted playsinline&gt;
  &lt;source src="https://ilovesymposia.com/napari/napari-coins-thresholding.mp4" type="video/mp4"&gt;&lt;/source&gt;
  &lt;source src="https://ilovesymposia.com/napari/napari-coins-thresholding.ogg" type="video/ogg"&gt;&lt;/source&gt;
  &lt;img src="https://ilovesymposia.com/napari/napari-coins-thresholding-frame.jpg" title="Your browser does not support the video tag."&gt;
&lt;/video&gt;

&lt;p&gt;This is not just a cute demo. I actually found this trick
&lt;a href="https://github.com/scikit-image/scikit-image/issues/4194#issuecomment-537420178"&gt;really useful&lt;/a&gt;
when investigating a bug in scikit-image. By varying the threshold
for h-maxima, I could see detections blinking in and out of existence, even
though they are supposed to only decrease as the parameter value is increased,
thus confirming that there is a bug in the scikit-image implementation of
h-maxima! 😬&lt;/p&gt;
&lt;p&gt;And indeed, improving that example for this post, the broadcasting works with
points, too, not just images!&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;image&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'heatmap.npy'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;viewer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;napari&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;view_image&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'original'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;colormap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'green'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                           &lt;span class="n"&gt;blending&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'additive'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;hmaxima&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;100.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;
&lt;span class="n"&gt;points&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nonzero&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;viewer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_points&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'maxima coordinates'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;opacity&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;result_image&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;viewer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_image&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'result'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;colormap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'magenta'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                &lt;span class="n"&gt;blending&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'additive'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;


&lt;video width="90%" controls autoplay loop muted playsinline&gt;
  &lt;source src="https://ilovesymposia.com/napari/napari-hmaxima-bug.mp4" type="video/mp4"&gt;&lt;/source&gt;
  &lt;source src="https://ilovesymposia.com/napari/napari-hmaxima-bug.ogg" type="video/ogg"&gt;&lt;/source&gt;
  &lt;img src="https://ilovesymposia.com/napari/napari-hmaxima-bug-frame.jpg" title="Your browser does not support the video tag."&gt;
&lt;/video&gt;

&lt;h3&gt;7. Overlay polygons&lt;/h3&gt;
&lt;p&gt;One of Nick's earliest contributions was one of his biggest: a vector-based
"shapes" layer for polygons, rectangles, circles, and other annotations. This
makes it very easy to replicate things like the &lt;a href="https://scikit-image.org/docs/dev/auto_examples/edges/plot_active_contours.html"&gt;active
contours&lt;/a&gt;
scikit-image example, without having to flip coordinates, because napari is an
image-first library:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;skimage&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;skimage&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;filters&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;skimage.color&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;rgb2gray&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;skimage.segmentation&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;active_contour&lt;/span&gt;


&lt;span class="n"&gt;astro&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astronaut&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;astro_gray&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;rgb2gray&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;astro&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;400&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;220&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;init&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;

&lt;span class="n"&gt;snake&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;active_contour&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filters&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gaussian&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;astro_gray&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                       &lt;span class="n"&gt;init&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.015&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;beta&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                       &lt;span class="n"&gt;gamma&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.001&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;coordinates&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'rc'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;viewer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;napari&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;view_image&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;astro&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rgb&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'astro'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;viewer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_shapes&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;init&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'initial'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                  &lt;span class="n"&gt;face_color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)],&lt;/span&gt;
                  &lt;span class="n"&gt;edge_color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'red'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;edge_width&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;
                  &lt;span class="n"&gt;shape_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'polygon'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;viewer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_shapes&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;snake&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'snake'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                  &lt;span class="n"&gt;face_color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)],&lt;/span&gt;
                  &lt;span class="n"&gt;edge_color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'blue'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;edge_width&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;
                  &lt;span class="n"&gt;shape_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'polygon'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;&lt;img alt="active contours" src="https://ilovesymposia.com/napari/astronaut-snake.png"&gt;&lt;/p&gt;
&lt;h3&gt;8. More!&lt;/h3&gt;
&lt;p&gt;Nick has been working hard to improve our
&lt;a href="https://github.com/napari/napari-tutorials"&gt;tutorials&lt;/a&gt;, which will have more
details about all of the above. Meanwhile, Ahmet Can and Bryant are busy making
it easier to use napari to view images live from a microscope, or another
source. We look forward to hearing more use cases from you! Your first point of
contact to ask for help should be the &lt;a href="https://forum.image.sc"&gt;image.sc forum&lt;/a&gt;
— don't forget to use the "napari" tag!  — as well as our &lt;a href="https://github.com/napari/napari"&gt;GitHub
issues&lt;/a&gt; for bug reports and feature requests.&lt;/p&gt;
&lt;p&gt;This might be a good time to emphasise that &lt;strong&gt;napari is still in alpha&lt;/strong&gt;, which
means that we might change the API at any time. This is not to discourage you
from using it, but rather to point out that you should be ready to evolve
quickly with it, or pin to the current minor version.&lt;/p&gt;
&lt;h2&gt;Our vision for the future&lt;/h2&gt;
&lt;p&gt;At the risk of sounding like a broken record, napari has already proven itself
insanely useful for all of us at the team, as well as a few extended members of
our community. But we are just getting started. We want to napari to help not
just Python practitioners, but also biologists and other scientists who want to
access Python's enormous scientific ecosystem, but don't necessarily want to
learn Python.&lt;/p&gt;
&lt;p&gt;We are &lt;a href="https://github.com/napari/napari/pull/263"&gt;working&lt;/a&gt; on a plugin system
to allow the data from napari layers to be the input to Python functions, and
have their outputs appear as new layers. A sneak peek:&lt;/p&gt;
&lt;video width="90%" controls autoplay loop muted playsinline&gt;
  &lt;source src="https://ilovesymposia.com/napari/napari-plugins-720p.mp4" type="video/mp4"&gt;&lt;/source&gt;
  &lt;source src="https://ilovesymposia.com/napari/napari-plugins-720p.ogg" type="video/ogg"&gt;&lt;/source&gt;
  &lt;img src="https://ilovesymposia.com/napari/napari-plugins-720p-frame.jpg" title="Your browser does not support the video tag."&gt;
&lt;/video&gt;

&lt;p&gt;We are building this in
&lt;a href="https://github.com/napari/napari/issues/140"&gt;collaboration&lt;/a&gt; with the
developers of &lt;a href="https://imjoy.io/"&gt;ImJoy&lt;/a&gt; to make our plugins cross-compatible.&lt;/p&gt;
&lt;p&gt;In addition to applying functions and seeing the outputs (what ImJoy's Wei
Ouyang refers to as &lt;em&gt;functional&lt;/em&gt; plugins), we see napari as a basis for more
complex interactivity, such as closed-loop learning in the style of
&lt;a href="https://www.ilastik.org/"&gt;Ilastik&lt;/a&gt;, skeleton tracing, 3D annotation, and more.
We already provide a framework to add or modify keyboard shortcuts or
mouse interactivity, so it's possible to write this functionality on top of
napari &lt;em&gt;now&lt;/em&gt;. But we want to provide a &lt;em&gt;unified&lt;/em&gt; framework that will prevent
plugins from clobbering each other's functionality.&lt;/p&gt;
&lt;p&gt;Our aim for the plugin framework is for every function to produce
valid and &lt;em&gt;readable&lt;/em&gt; Python code, so that path from performing a set of
operations to producing a Python module — and thus a plugin — is perfectly
smooth.&lt;/p&gt;
&lt;p&gt;At the March CZI meeting, someone asked me whether we would
provide a headless mode for napari processing. Yes and no: Our motto developing
the plugin system is that &lt;em&gt;napari-headless is just Python.&lt;/em&gt;
With the recording capability and built-in IPython console, we think that
napari could be a platform to teach
non-computational scientists the basics of Python, thus providing an
accelerated loop converting scientists from users to plugin
contributors, and then to library contributors, and improving the whole
ecosystem in the process.&lt;/p&gt;
&lt;h2&gt;Join us!&lt;/h2&gt;
&lt;p&gt;In a little over a year, napari has grown beyond what I thought possible. But
we still have a lot of work to do! In addition to our &lt;a href="https://github.com/napari/napari/issues"&gt;issues
list&lt;/a&gt;, we have an &lt;a href="https://github.com/napari/napari/issues/420"&gt;open
roadmap&lt;/a&gt;. Feel free to jump in and
join the fray!&lt;/p&gt;
&lt;p&gt;We also encourage you to contribute to the many open source projects on which we
depend, starting with VisPy: if you have OpenGL experience, they could really
use your help! Other libraries we build on include
NumPy, SciPy, IPython, QtConsole, ImageIO, scikit-image, QtPy, and PyOpenGL.&lt;/p&gt;
&lt;h2&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;I've tried to name people's contributions to napari as they happened, but so
many have helped to build it, it was impossible to name everyone. Our
ever-growing &lt;a href="https://github.com/napari/napari/graphs/contributors"&gt;committers list&lt;/a&gt;
can be found on GitHub, but many more have contributed in countless ways. CZI's
Shannon Axelrod and Ambrose Carr helped us make early design decisions when they
adopted napari as the main viewer for StarFISH. Charlotte Weaver helped us build
a (still upcoming) binary installer, and serves on our &lt;a href="https://github.com/napari/napari/blob/master/docs/CODE_OF_CONDUCT.md"&gt;Code of
Conduct&lt;/a&gt;
(modelled after SciPy's). Greg Johnson and his team at the Allen Institute have
used napari to build a corpus of annotated images — and helped drive
the design of napari for that use case.&lt;/p&gt;
&lt;p&gt;At the Imaging Kickoff Meeting last March, since CZI had invited me, I was
staying at a hotel downtown rather than at Loïc's. One night, Loïc sent me an
exasperated message that still brings a smile to my face: “You know, if you'd
stayed at your stupid hotel a year ago, there would be no napari.” It
constantly amazes me how many things had to line up for napari to exist, let
alone be where it is today.&lt;/p&gt;
&lt;p&gt;I'm so grateful to everyone who has helped napari get to get to this point. If
I haven't mentioned your contribution, please email me and I'll make it right.
One nice thing about blog posts is that they are easy to update!&lt;/p&gt;&lt;/div&gt;</description><category>Fiji</category><category>napari</category><category>NumPy</category><category>Planet SciPy</category><category>programming</category><category>Python</category><category>SciPy</category><category>software</category><guid>https://ilovesymposia.com/2019/10/24/introducing-napari-a-fast-n-dimensional-image-viewer-in-python/</guid><pubDate>Thu, 24 Oct 2019 13:59:54 GMT</pubDate></item><item><title>The road to scikit-image 1.0</title><link>https://ilovesymposia.com/2018/07/13/the-road-to-scikit-image-1-0/</link><dc:creator>Juan Nunez-Iglesias</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;This is the first in a series of posts about the joint scikit-image, scikit-learn, and dask sprint that took place at the Berkeley Insitute of Data Science, May 28-Jun 1, 2018.&lt;/p&gt;
&lt;p&gt;In addition to the dask and scikit-learn teams, the sprint brought together three core developers of scikit-image (Emmanuelle Gouillart, Stéfan van der Walt, and myself), and two newer contributors, Kira Evans and Mark Harfouche. Since we are rarely in the same timezone, let alone in the same room, we took the opportunity to discuss some high level goals using a framework suggested by Tracy Teal (via Chris Holdgraf): &lt;em&gt;Vision, Mission, Values&lt;/em&gt;. I'll try do Chris's explanation of these ideas justice:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Vision: what are we trying to achieve? What is the future that we are trying to bring about?&lt;/li&gt;
&lt;li&gt;Mission: what are we going to do about it? This is the &lt;em&gt;plan&lt;/em&gt; needed to make the vision a reality.&lt;/li&gt;
&lt;li&gt;Values: what are we &lt;em&gt;willing&lt;/em&gt; to do, and &lt;em&gt;not&lt;/em&gt; willing to do, to complete our mission?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, on the basis of this framework, I'd like to review where scikit-image is now, where I think it needs to go, and the ideas that Emma, Stéfan, and I came up with during the sprint to get scikit-image there.&lt;/p&gt;
&lt;p&gt;I will point out, from the beginning, that one of our values is that we are &lt;em&gt;community-driven&lt;/em&gt;, and this is not a wishy-washy concept. (More below.) Therefore this blog post constitutes only a preliminary document, designed to kick-start an &lt;em&gt;official roadmap&lt;/em&gt; for scikit-image 1.0 with more than a blank canvas. The roadmap will be debated on GitHub and the mailing list, open to discussion by anyone, and when completed will appear on our webpage. &lt;em&gt;This post is not the roadmap.&lt;/em&gt;&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;h3&gt;Part one: where we are&lt;/h3&gt;

&lt;p&gt;scikit-image is a tremendously successful project that I feel very proud to have been a part of until now. I still cherish the email I got from Stéfan inviting me to join the core team. (Five years ago now!)&lt;/p&gt;
&lt;p&gt;Like many open source projects, though, we are threatened by our own success, with feature requests and bug reports piling on faster than we can get through them. And, because we grew organically, with no governance model, it is often difficult to resolve thorny questions about API design, what gets included in the library, and how to deprecate old functionality. Discussion usually stalls before any decision is taken, resulting in a process heavily biased towards inaction. Many issues and PRs languish for years, resulting in a double loss for the project: a smaller loss from losing the PR, and a bigger one from losing a potential contributor that understandably has lost interest.&lt;/p&gt;
&lt;p&gt;Possibly the most impactful decision that we took at the BIDS sprint is that at least three core developers will video once a month to discuss stalled issues and PRs. (The logistics are still being worked out.) We hope that this sustained commitment will move many PRs and issues forward much faster than they have until now.&lt;/p&gt;
&lt;h3&gt;Part two: where we're going&lt;/h3&gt;

&lt;p&gt;Onto the framework. What are the vision, mission, and values of scikit-image? How will these help guide the decisions that we make daily and in our dev meetings?&lt;/p&gt;
&lt;h4&gt;Our vision&lt;/h4&gt;

&lt;p&gt;We want scikit-image to be &lt;em&gt;the&lt;/em&gt; reference image processing and analysis library for science in Python. In one sense I think that we are already there, but there are more than enough remaining warts that they might cause the motivated user to go looking elsewhere. The vision, then, is to increase our customer satisfaction fraction in this space to something approaching 1.0.&lt;/p&gt;
&lt;h4&gt;Our mission&lt;/h4&gt;

&lt;p&gt;How do we get there? Here is our mission:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Our library must be &lt;strong&gt;easily re-usable.&lt;/strong&gt; This means that we will be careful in adding new dependencies, and possibly cull some existing ones, or make them optional. We also want to remove some of the bigger test datasets from our package, which at 24MB is getting rather unwieldy! (By comparison, Python 3.7 is 16MB.) (Props to Josh Warner for noticing this.)&lt;/li&gt;
&lt;li&gt;It also means providing a &lt;strong&gt;consistent API.&lt;/strong&gt; This means that conceptually identical function arguments, such as images, label images, and arguments defining whether an input image is grayscale, should have the same name across various the library. We've made great strides in this goal thanks to Egor Panfilov and &lt;a href="https://github.com/scikit-image/scikit-image/issues/2538"&gt;Adrian Sieber&lt;/a&gt;, but we still have some way to go.&lt;/li&gt;
&lt;li&gt;We want to &lt;strong&gt;ensure accuracy&lt;/strong&gt; of our algorithms. This means comprehensive testing, even against external libraries, and engaging experts in relevant fields to audit our code. (Though this of course is a challenge!)&lt;/li&gt;
&lt;li&gt;Show utmost &lt;strong&gt;care with users' data&lt;/strong&gt;. Not that we haven't cared until now, but there are places in scikit-image where too much responsibility (in my view) rests with the user, with insufficient transparency from our functions for new users to predict what will happen to their data. For example, we are quite liberal with how we deal with input data: it gets rescaled whenever we need to change the type, for example from unsigned 8-bit integers (uint8) to floating point. Although we have &lt;a href="https://github.com/scikit-image/scikit-image/issues/2677#issuecomment-309717979"&gt;good technical reasons&lt;/a&gt; for doing this, and rather &lt;a href="http://scikit-image.org/docs/dev/user_guide/data_types.html"&gt;extensive documentation about it&lt;/a&gt;, these conversions are the source of much user confusion. We are aiming to improve this in &lt;a href="https://github.com/scikit-image/scikit-image/issues/3009"&gt;issue 3009&lt;/a&gt;. Likewise, we don't handle image metadata at all. What is the physical extent of the input image? What is the range and units of the data points in the image? What do the different channels represent? These are all important questions in scientific images, but until now we have completely abdicated responsibility in them and simply ignore any metadata. I don't think this is tenable for a scientific imaging library. We don't have a good answer for how we will do it, but I consider this a must-solve before we can call ourselves 1.0.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Our values&lt;/h4&gt;

&lt;p&gt;Finally, how do we solve the thorny questions of API design, whether to include algorithms, etc? Here are our values:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We used the word "reference" in our vision. This phrasing is significant. It means that &lt;strong&gt;we value elegant implementations&lt;/strong&gt;, that are &lt;em&gt;easy to understand for newcomers&lt;/em&gt;, over obtaining every last ounce of speed. This value is a useful guide in reviewing pull requests. We will prefer a 20% slowdown when it reduces the lines of code two-fold.&lt;/li&gt;
&lt;li&gt;We also used the word &lt;em&gt;science&lt;/em&gt; in our vision. This means our aim is to &lt;strong&gt;serve scientific applications&lt;/strong&gt;, and not, for example, image editing in the vein of Photoshop or GIMP. Having said this, we value being part of diverse scientific fields. (One of the first citations of the scikit-image paper was a remote sensing paper, to our delight: none of the core developers work in that field!)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;We are inclusive.&lt;/strong&gt; From my first contributions to the project, I have received patient mentorship from Stéfan, Emmanuelle, Johannes Schönberger, Andy Mueller, and others. (Indeed, I am still learning from fellow contributors, as seen &lt;a href="https://github.com/scikit-image/scikit-image/pull/3031#issuecomment-398961212"&gt;here&lt;/a&gt;, to show just one example.) We will continue to welcome and mentor newcomers to the Scientific Python ecosystem who are making their first contribution.&lt;/li&gt;
&lt;li&gt;Both of the above points have a corrolary: &lt;strong&gt;we require excellent documentation&lt;/strong&gt;, in the form of usage examples, docstrings documenting the API of each function, and comments explaining tricky parts of the code. This requirement has stalled a few PRs in the past, but this is something that our monthly meetings will specifically address.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;We don't do magic.&lt;/strong&gt; We use NumPy arrays instead of fancy façade objects that mask their complexity. We prefer to educate our users over making decisions on their behalf (through quality documentation, particularly in docstrings).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;We are community-driven&lt;/strong&gt;, which means that decisions about the API and features will be driven by our users' requirements, and not the whims of the core team. (For example, I would happily &lt;a href="http://toolz.readthedocs.io/en/latest/curry.html"&gt;curry&lt;/a&gt; all of our functions, but that would be confusing to most users, so I suffer in silence. =P)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I hope that the above values are uncontroversial in the scikit-image core team. (I myself used to fall heavily on the pro-magic side, but hard experience with this library has shown me the error of my ways.) I also hope, but more hesitantly, that our much wider community of users will also see these values as, well, valuable.&lt;/p&gt;
&lt;p&gt;As I mentioned above, I hope this blog post will spawn a discussion involving both the core team and the wider community, and that this discussion can be distilled into a public roadmap for scikit-image.&lt;/p&gt;
&lt;h3&gt;Part three: scikit-image 1.0&lt;/h3&gt;

&lt;p&gt;I have deliberately left out new features off the mission, except for metadata handling. The library will never be "feature complete". But we &lt;em&gt;can&lt;/em&gt; develop a stable and consistent enough API that adding new features will almost never require breaking it.&lt;/p&gt;
&lt;p&gt;For completeness, I'll compile my personal pet list of things I will attempt to work on or be particularly excited about other people working on. This is &lt;em&gt;not&lt;/em&gt; part of the roadmap, it's part of my roadmap.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Near-complete support for n-dimensional data. I want 2D-only functions to become the exception in the library, maybe so much so that we are forced to add a &lt;code&gt;_2d&lt;/code&gt; suffix to the function name.&lt;/li&gt;
&lt;li&gt;Typing support. I never want to move from simple arrays as our base data type, but I want a way to systematically distinguish between plain images, label images, coordinate lists, and other types, in a way that is accessible to automatic tools.&lt;/li&gt;
&lt;li&gt;Basic image registration functionality.&lt;/li&gt;
&lt;li&gt;Evaluation algorithms for all parts of the library (such as segmentation, or keypoint matching).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;The human side&lt;/h3&gt;

&lt;p&gt;Along with articulating the way we see the project, another key part of getting to 1.0 is supporting existing maintainers, and onboarding new ones. It is clear that the project is currently straining under the weight of its popularity. While we solve one issue, three more are opened, and two pull requests.&lt;/p&gt;
&lt;p&gt;In the past, we have been too hesitant to invite new members to the core team, because it is difficult to tell whether a new contributor shares your vision. Our roadmap document is an important step towards rectifying this, because it clarifies where the library is going, and therefore the decision making process when it comes to accepting new contributions, for example.&lt;/p&gt;
&lt;p&gt;In a followup to this post, I aim to propose a &lt;em&gt;maintainer onboarding document&lt;/em&gt;, in a similar vein, to make sure that new maintainers all share the same process when evaluating new PRs and communicating with contributors. A governance model is also in the works, by which I mean that Stéfan has been wanting to establish one for years and now Emmanuelle and I are onboard with this plan, and I hope others will be too, and now we just need to decide on the damn thing.&lt;/p&gt;
&lt;p&gt;I hope that all of these changes will allows us to reach the scikit-image 1.0 milestone sooner rather than later, and that everyone reading this is as excited about it as I was while we hashed this plan together.&lt;/p&gt;
&lt;p&gt;As a reminder, &lt;strong&gt;this is not our final roadmap&lt;/strong&gt;, nor our final &lt;strong&gt;vision/mission statement&lt;/strong&gt;. Please comment on the corresponding &lt;a href="https://github.com/scikit-image/scikit-image/issues/3263"&gt;GitHub issue&lt;/a&gt; for this post if you have thoughts and suggestions! (You can also use the &lt;a href="https://mail.python.org/mailman/listinfo/scikit-image"&gt;mailing list&lt;/a&gt;, and we will soon provide a way to submit anonymous comments, too.) As a community, we will come together to create the library we all want to use and contribute to.&lt;/p&gt;
&lt;p&gt;As a reminder, everything in this blog is &lt;a href="https://dancohen.org/2013/11/26/cc0-by/"&gt;CC0+BY&lt;/a&gt;, so feel free to reuse any or all of it in your own projects! And I want to thank BIDS, and specifically Nelle Varoquaux at BIDS, for making this discussion possible, among many other things that will be written up in upcoming posts.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; Anonymous comments are now open at https://pollev.com/juannunezigl611. To summarise, to comment on this proposal you can:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;comment on the &lt;a href="https://github.com/scikit-image/scikit-image/issues/3263"&gt;GitHub issue&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;submit a comment below&lt;/li&gt;
&lt;li&gt;submit an anonymous comment at https://pollev.com/juannunezigl611&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;/p&gt;&lt;/div&gt;</description><category>image analysis</category><category>open-source</category><category>Planet SciPy</category><category>programming</category><category>Python</category><category>software</category><guid>https://ilovesymposia.com/2018/07/13/the-road-to-scikit-image-1-0/</guid><pubDate>Thu, 12 Jul 2018 18:58:35 GMT</pubDate></item><item><title>An update on mixing Java and Python with Fiji</title><link>https://ilovesymposia.com/2014/03/15/an-update-on-mixing-java-and-python-with-fiji/</link><dc:creator>Juan Nunez-Iglesias</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Two weeks ago I &lt;a href="http://ilovesymposia.com/2014/02/26/fiji-jython/"&gt;posted&lt;/a&gt; about invoking ImageJ functions from Python using Fiji’s Jython interpreter. A couple of updates on the topic: &lt;/p&gt;
&lt;p&gt;First, I’ve made a &lt;a href="https://github.com/jni/fiji-python"&gt;repository&lt;/a&gt; with a template project encapsulating my tips from that post. It’s very simple to get a Fiji Jython script working from that template. As an example, &lt;a href="https://github.com/jni/snemi-eval"&gt;here’s&lt;/a&gt; a script to evaluate segmentations using the metric used by the &lt;a href="https://ilovesymposia.com/2014/03/15/an-update-on-mixing-java-and-python-with-fiji/brainiac2.mit.edu/SNEMI3D/"&gt;SNEMI3D segmentation challenge&lt;/a&gt; (a slightly modified version of the adapted Rand error). &lt;/p&gt;

&lt;p&gt;Second, this entire discussion might be rendered obsolete by two incredible projects from the &lt;a href="http://www.cellprofiler.org/"&gt;CellProfiler&lt;/a&gt; team: &lt;a href="https://github.com/CellProfiler/python-javabridge"&gt;Python-Javabridge&lt;/a&gt;, which allows Python to interact seamlessly with Java code, and &lt;a href="https://github.com/CellProfiler/python-bioformats"&gt;Python-Bioformats&lt;/a&gt;, which uses Python-Javabridge to read Bioformats images into Python. I have yet to play with them, but both look like cleaner alternatives to interact with ImageJ than my Jython scripting! At some point I’ll write a post exploring these tools, but if you get to it before me, please mention it in the comments!&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;&lt;/div&gt;</description><category>Fiji</category><category>Fiji Jython</category><category>Jython</category><category>Planet SciPy</category><category>programming</category><category>Python</category><category>Python-Bioformats</category><category>Python-Javabridge</category><category>software</category><guid>https://ilovesymposia.com/2014/03/15/an-update-on-mixing-java-and-python-with-fiji/</guid><pubDate>Fri, 14 Mar 2014 15:21:06 GMT</pubDate></item><item><title>Get the best of both worlds with Fiji's Jython interpreter</title><link>https://ilovesymposia.com/2014/02/26/fiji-jython/</link><dc:creator>Juan Nunez-Iglesias</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;/p&gt;&lt;a href="http://fiji.sc"&gt;Fiji is just ImageJ&lt;/a&gt;, with batteries included. It contains plugins to do virtually anything you would want to do to an image. Since my go-to programming language is Python, my favorite feature of Fiji is its language-agnostic API, which supports a plethora of languages, including Java, Javascript, Clojure, and of course Python; 7 languages in all. (Find these under Plugins/Scripting/Script Editor.) Read on to learn more about the ins and outs of using Python to drive Fiji.
&lt;p&gt;Among the plugin smorgasbord of Fiji is the Bio-Formats importer, which can open any proprietary microscopy file under the sun. (And there’s a lot of them!) Below I will use Jython to open some .lifs, do some processing, and output some .pngs that I can process further using Python/NumPy/scikit-image. (A .lif is a Leica Image File, because there were not enough image file formats before Leica came along.)&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;p&gt;The first thing to note is that Jython is not Python, and it is certainly not Python 2.7. In fact, the Fiji Jython interpreter implements Python 2.5, which means no &lt;code&gt;argparse&lt;/code&gt;. Not to worry though, as &lt;code&gt;argparse&lt;/code&gt; is implemented in a &lt;a href="https://code.google.com/p/argparse/source/browse/argparse.py"&gt;single, pure Python file&lt;/a&gt; distributed under the Python license. So:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip #1: copy argparse.py into your project.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This way you’ll have access the state of the art in command line argument processing from within the Jython interpreter.&lt;/p&gt;
&lt;p&gt;To get Fiji to run your code, you simply feed it your source file on the command line. So, let’s try it out with a simple example, &lt;code&gt;echo.py&lt;/code&gt;:
&lt;/p&gt;&lt;pre&gt;&lt;code class="python"&gt;import argparse
&lt;p&gt;if &lt;strong&gt;name&lt;/strong&gt; == '&lt;strong&gt;main&lt;/strong&gt;':
    parser = argparse.ArgumentParser(description=
                                     "Parrot back your arguments.")
    parser.add_argument('args', nargs="*", help="The input arguments.")
    args = parser.parse_args()
    for arg in args.args:
        print(arg)&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;/code&gt;&lt;/pre&gt;
Now we can just run this:
&lt;pre&gt;&lt;code&gt;$ fiji echo.py hello world
hello
world
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But sadly, Fiji captures any -h calls, which defeats the purpose of using argparse in the first place!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ fiji echo.py -h
Usage: /Applications/Fiji.app/Contents/MacOS/fiji-macosx [&amp;lt;Java options&amp;gt;.. --] [&amp;lt;ImageJ options&amp;gt;..] [&amp;lt;files&amp;gt;..]

Java options are passed to the Java Runtime, ImageJ
options to ImageJ (or Jython, JRuby, ...).

In addition, the following options are supported by ImageJ:
General options:
--help, -h
    show this help
--dry-run
    show the command line, but do not run anything
--debug
    verbose output
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(… and so on, the output is quite huge.)&lt;/p&gt;
&lt;p&gt;(Note also that I aliased the Fiji binary, that long path under &lt;code&gt;/Applications&lt;/code&gt;, to a simple &lt;code&gt;fiji&lt;/code&gt; command; I recommend you do the same.)&lt;/p&gt;
&lt;p&gt;However, we can work around this by calling help using &lt;em&gt;Python&lt;/em&gt; as the interpreter, and only using Fiji to actually run the file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ python echo.py -h
usage: echo.py [-h] [args [args ...]]

Parrot back your arguments.

positional arguments:
  args        The input arguments.

optional arguments:
  -h, --help  show this help message and exit&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That’s more like it! Now we can start to build something a bit more interesting, for example, something that converts arbitrary image files to png:
&lt;/p&gt;&lt;pre&gt;&lt;code class="python"&gt;import argparse
from ij import IJ # the IJ class has utility methods for many common tasks.
&lt;p&gt;def convert_file(fn):
    """Convert the input file to png format.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gh"&gt;Parameters&lt;/span&gt;
&lt;span class="gh"&gt;----------&lt;/span&gt;
fn : string
    The filename of the image to be converted.
"""
imp = IJ.openImage(fn)
# imp is the common name for an ImagePlus object,
# ImageJ's base image class
fnout = fn.rsplit('.', 1)[0] + '.png'
IJ.saveAs(imp, 'png', fnout)
&lt;/pre&gt;


&lt;p&gt;if &lt;strong&gt;name&lt;/strong&gt; == '&lt;strong&gt;main&lt;/strong&gt;':
    parser = argparse.ArgumentParser(description="Convert TIFF to PNG.")
    parser.add_argument('images', nargs='+', help="Input images.")&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;args = parser.parse_args()
for fn in args.images:
    convert_file(fn)
&lt;/pre&gt;


&lt;p&gt;&lt;/p&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Boom, we’re done. But wait, we actually broke the Python interpreter compatibility, since ij is not a Python library!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ python convert2png.py -h
Traceback (most recent call last):
  File "convert.py", line 2, in &amp;lt;module&amp;gt;
    from ij import IJ # the IJ class has utility methods for many common tasks.
ImportError: No module named ij
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which brings us to:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip #2: only import Java API functions within the functions that use them.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;By moving the &lt;code&gt;from ij import IJ&lt;/code&gt; statement into the &lt;code&gt;convert&lt;/code&gt; function, we maintain compatibility with Python, and can continue to use &lt;code&gt;argparse&lt;/code&gt;’s helpful documentation strings.&lt;/p&gt;
&lt;p&gt;Next, we want to use the Bio-Formats importer, which is class &lt;code&gt;BF&lt;/code&gt; in &lt;code&gt;loci.plugins&lt;/code&gt;. Figuring out the class hierarchy for arbitrary plugins is tricky, but you can find it &lt;a href="http://rsbweb.nih.gov/ij/developer/api/index.html"&gt;here&lt;/a&gt; for core ImageJ (using lovely 1990s-style frames) and &lt;a href="http://ci.openmicroscopy.org/job/BIOFORMATS-5.0-latest/javadoc/index.html"&gt;here&lt;/a&gt; for Bio-Formats, and Curtis Rueden has made &lt;a href="http://javadoc.imagej.net/"&gt;this list&lt;/a&gt; for other common plugins.&lt;/p&gt;
&lt;p&gt;When you try to open a file with Bio-Formats importer using the Fiji GUI, you get the following dialog:&lt;/p&gt;
&lt;figure&gt;&lt;img alt="BioFormats import window" src="http://ilovesymposia.files.wordpress.com/2014/02/bioformats-window.png"&gt; &lt;figcaption&gt;BioFormats import window&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;That’s a lot of options, and we actually want to set some of them. If you look at the &lt;a href="http://ci.openmicroscopy.org/job/BIOFORMATS-5.0-latest/javadoc/loci/plugins/BF.html#openImagePlus(loci.plugins.in.ImporterOptions)"&gt;&lt;code&gt;BF.openImagePlus&lt;/code&gt;&lt;/a&gt; documentation, you can see that this is done through an &lt;code&gt;ImporterOptions&lt;/code&gt; class located in &lt;code&gt;loci.plugins.in&lt;/code&gt;. You’ll notice that “in” is a reserved word in Python, so &lt;code&gt;from loci.plugins.in import ImporterOptions&lt;/code&gt; is not a valid Python statement. Yay! My workaround:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip #3: move your Fiji imports to an external file.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;So I have a &lt;code&gt;jython_imports.py&lt;/code&gt; file with just:&lt;/p&gt;
&lt;pre&gt;&lt;code class="python"&gt;from ij import IJ
from loci.plugins import BF
from loci.plugins.in import ImporterOptions
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then, inside the &lt;code&gt;convert_files()&lt;/code&gt; function, we just do:&lt;/p&gt;
&lt;pre&gt;&lt;code class="python"&gt;
from jython_imports import IJ, BF, ImporterOptions
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This way, the main file remains Python-compatible until the convert() function is actually called, regardless of whatever funky and unpythonic stuff is happening in &lt;code&gt;jython_imports.py&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Onto the options. If you untick “Open files individually”, it will open up all matching files in a directory, regardless of your input filename! Not good. So now we play a pattern-matching game in which we match the option description in the above dialog with the &lt;a href="http://ci.openmicroscopy.org/job/BIOFORMATS-5.0-latest/javadoc/loci/plugins/in/ImporterOptions.html"&gt;ImporterOptions API&lt;/a&gt; calls. In this case, we &lt;code&gt;setUngroupFiles(True)&lt;/code&gt;. To specify a filename, we &lt;code&gt;setId(filename)&lt;/code&gt;. Additionally, because we want all of the images in the .lif file, we &lt;code&gt;setOpenAllSeries(True)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Next, each image in the series is 3D and has three channels, but we are only interested in a summed z-projection of the first channel. There’s a set of ImporterOptions methods tantalizingly named &lt;code&gt;setCBegin&lt;/code&gt;, &lt;code&gt;setCEnd&lt;/code&gt;, and &lt;code&gt;setCStep&lt;/code&gt;, but this is where I found the &lt;a href="http://ci.openmicroscopy.org/job/BIOFORMATS-5.0-latest/javadoc/loci/plugins/in/ImporterOptions.html#setCEnd(int,%20int)"&gt;documentation&lt;/a&gt; sorely lacking. The functions take &lt;code&gt;(int s, int value)&lt;/code&gt; as arguments, but what’s &lt;code&gt;s&lt;/code&gt;??? Are the limits closed or open? Code review is a wonderful thing, and this would not have passed it. To figure things out:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip #4: use Fiji’s interactive Jython interpreter to figure things out quickly.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You can find the Jython interpreter under Plugins/Scripting/Jython Interpreter. It’s no IPython, but it is extremely helpful to answer the questions I had above. My hypothesis was that &lt;code&gt;s&lt;/code&gt; was the series, and that the intervals would be closed. So:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;loci.plugins&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;BF&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;loci.plugins.in&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;ImporterOptions&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;opts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ImporterOptions&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;opts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setId&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"myFile.lif"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;opts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setOpenAllSeries&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;opts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setUngroupFiles&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;imps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BF&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;openImagePlus&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;opts&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;Now we can play around, with one slight annoyance: the interpreter won’t print the output of your last statement, so you have to specify it:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;imps&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;imps&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="mi"&gt;18&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;Which is what I expected, as there are 18 series in my .lif file. The image shape is given by the &lt;code&gt;getDimensions()&lt;/code&gt; method of the ImagePlus class:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;imps&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getDimensions&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'i'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1024&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;31&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;imps&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getDimensions&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'i'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1024&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;34&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;pre&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="n"&gt;That&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;channels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;Now, let’s try the same thing with &lt;code&gt;setCEnd&lt;/code&gt;, assuming closed interval:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;opts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setCEnd&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;## only read channels up to 0 for series 0?&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;opts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setCEnd&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;## only read channels up to 0 for series 2?&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;imps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BF&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;openImagePlus&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;opts&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;imps&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getDimensions&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'i'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1024&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;31&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;imps&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getDimensions&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'i'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1024&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;34&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;imps&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getDimensions&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'i'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1024&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;Nothing there to disprove my hypothesis! So we move on to the final step, which is to z-project the stack by summing the intensity over all z values. This is normally accessed via Image/Stacks/Z Project in the Fiji GUI, and I found the corresponding &lt;code&gt;ij.plugin.ZProjector&lt;/code&gt; class by searching for &lt;a href="http://rsbweb.nih.gov/ij/developer/api/ij/plugin/ZProjector.html"&gt;“proj” in the ImageJ documentation&lt;/a&gt;. A &lt;code&gt;ZProjector&lt;/code&gt; object has a &lt;code&gt;setMethod&lt;/code&gt; method that usefully takes an int as an argument, with no explanation in its docstring as to which int translates to which method (sum, average, max, etc.). A little more digging in the &lt;a href="http://rsb.info.nih.gov/ij/developer/source/ij/plugin/ZProjector.java.html"&gt;source code&lt;/a&gt; reveals some class static variables, &lt;code&gt;AVG_METHOD&lt;/code&gt;, &lt;code&gt;MAX_METHOD&lt;/code&gt;, and so on.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip #5: don’t be afraid to look at the source code. It’s one of the main advantages of working in open-source.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;So:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;ij.plugin&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;ZProjector&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;proj&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ZProjector&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;proj&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setMethod&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ZProjector&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SUM_METHOD&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;proj&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setImage&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;imps&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;proj&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;doProjection&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;impout&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;proj&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getProjection&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;impout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getDimensions&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'i'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1024&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;The output is actually a float-typed image, which will get rescaled to [0, 255] uint8 on save if we don’t fix it. So, to wrap up, we convert the image to 16 bits (making sure to &lt;a href="https://groups.google.com/d/msg/fiji-users/HfuHj0QBo40/CR9s3MQ5vUsJ"&gt;turn off scaling&lt;/a&gt;), use the series title to generate a unique filename, and save as a PNG:
&lt;/p&gt;&lt;pre&gt;&lt;code class="python"&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;ij.process&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;ImageConverter&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;ImageConverter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setDoScaling&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;conv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ImageConverter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;impout&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;conv&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;convertToGray16&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;imps&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getTitle&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rsplit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;" "&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;IJ&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;saveAs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;impout&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'png'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"myFile-"&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;".png"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;You can see the final result of my sleuthing in &lt;a href="https://github.com/jni/lesion/blob/6f77cccd1e0f3ddf92ce35a7040ada5328fd90ff/lesion/lif2png.py"&gt;lif2png.py&lt;/a&gt; and &lt;a href="https://github.com/jni/lesion/blob/6f77cccd1e0f3ddf92ce35a7040ada5328fd90ff/lesion/jython_imports.py"&gt;jython_imports.py&lt;/a&gt;. If you would do something differently, pull requests are always welcome.&lt;/p&gt;
&lt;p&gt;Before I sign off, let me recap my tips:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;copy argparse.py into your project;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;only import Java API functions within the functions that use them;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;move your Fiji imports to an external file;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;use Fiji’s interactive Jython interpreter to figure things out quickly; and&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;don’t be afraid to look at the source code.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;And let me add a few final comments: once I started digging into all of Fiji’s plugins, I found documentation of very variable quality, and worse, virtually zero consistency between the interfaces to each plugin. Some work on “the currently active image”, some take an &lt;code&gt;ImagePlus&lt;/code&gt; instance as input, and others still a filename or a directory name. Outputs are equally variable. This has been a huge pain when trying to work with these plugins.&lt;/p&gt;
&lt;p&gt;But, on the flipside, this is the most complete collection of image processing functions anywhere. Along with the seamless access to all those functions from Jython and other languages, that makes Fiji very worthy of your attention.
&lt;/p&gt;&lt;h4 id="acknowledgements"&gt;Acknowledgements&lt;/h4&gt;
This post was possible thanks to the help of &lt;a href="http://albert.rierol.net/"&gt;Albert Cardona&lt;/a&gt;, &lt;a href="http://loci.wisc.edu/people/johannes-schindelin"&gt;Johannes Schindelin&lt;/a&gt;, &lt;a href="http://loci.wisc.edu/people/wayne-rasband"&gt;Wayne Rasband&lt;/a&gt;, and &lt;a href="http://lammertlab.org/Jan_Eglinger"&gt;Jan Eglinger&lt;/a&gt;, who restlessly respond to (it seems) every query on the &lt;a href="http://imagej.1557.x6.nabble.com/"&gt;ImageJ mailing list&lt;/a&gt;. Thanks!
&lt;h4 id="reference"&gt;References&lt;/h4&gt;
&lt;p&gt;&lt;span class="Z3988" title="ctx_ver=Z39.88-2004&amp;amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;amp;rft.jtitle=Nature+methods&amp;amp;rft_id=info%3Apmid%2F22743772&amp;amp;rfr_id=info%3Asid%2Fresearchblogging.org&amp;amp;rft.atitle=Fiji%3A+an+open-source+platform+for+biological-image+analysis.&amp;amp;rft.issn=1548-7091&amp;amp;rft.date=2012&amp;amp;rft.volume=9&amp;amp;rft.issue=7&amp;amp;rft.spage=676&amp;amp;rft.epage=82&amp;amp;rft.artnum=&amp;amp;rft.au=Schindelin+J&amp;amp;rft.au=Arganda-Carreras+I&amp;amp;rft.au=Frise+E&amp;amp;rft.au=Kaynig+V&amp;amp;rft.au=Longair+M&amp;amp;rft.au=Pietzsch+T&amp;amp;rft.au=Preibisch+S&amp;amp;rft.au=Rueden+C&amp;amp;rft.au=Saalfeld+S&amp;amp;rft.au=Schmid+B&amp;amp;rft.au=Tinevez+JY&amp;amp;rft.au=White+DJ&amp;amp;rft.au=Hartenstein+V&amp;amp;rft.au=Eliceiri+K&amp;amp;rft.au=Tomancak+P&amp;amp;rft.au=Cardona+A&amp;amp;rfe_dat=bpr3.included=1;bpr3.tags=Biology%2CComputer+Science+%2F+Engineering%2CComputational+Biology%2C+Bioinformatics"&gt;Schindelin J, Arganda-Carreras I, Frise E, Kaynig V, Longair M, Pietzsch T, Preibisch S, Rueden C, Saalfeld S, Schmid B, Tinevez JY, White DJ, Hartenstein V, Eliceiri K, Tomancak P, &amp;amp; Cardona A (2012). Fiji: an open-source platform for biological-image analysis. &lt;span style="font-style:italic;"&gt;Nature methods, 9&lt;/span&gt; (7), 676-82 PMID: &lt;a rev="review" href="http://www.ncbi.nlm.nih.gov/pubmed/22743772"&gt;22743772&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="Z3988" title="ctx_ver=Z39.88-2004&amp;amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;amp;rft.jtitle=The+Journal+of+cell+biology&amp;amp;rft_id=info%3Apmid%2F20513764&amp;amp;rfr_id=info%3Asid%2Fresearchblogging.org&amp;amp;rft.atitle=Metadata+matters%3A+access+to+image+data+in+the+real+world.&amp;amp;rft.issn=0021-9525&amp;amp;rft.date=2010&amp;amp;rft.volume=189&amp;amp;rft.issue=5&amp;amp;rft.spage=777&amp;amp;rft.epage=82&amp;amp;rft.artnum=&amp;amp;rft.au=Linkert+M&amp;amp;rft.au=Rueden+CT&amp;amp;rft.au=Allan+C&amp;amp;rft.au=Burel+JM&amp;amp;rft.au=Moore+W&amp;amp;rft.au=Patterson+A&amp;amp;rft.au=Loranger+B&amp;amp;rft.au=Moore+J&amp;amp;rft.au=Neves+C&amp;amp;rft.au=Macdonald+D&amp;amp;rft.au=Tarkowska+A&amp;amp;rft.au=Sticco+C&amp;amp;rft.au=Hill+E&amp;amp;rft.au=Rossner+M&amp;amp;rft.au=Eliceiri+KW&amp;amp;rft.au=Swedlow+JR&amp;amp;rfe_dat=bpr3.included=1;bpr3.tags=Biology%2CComputer+Science+%2F+Engineering%2CComputational+Biology%2C+Bioinformatics"&gt;Linkert M, Rueden CT, Allan C, Burel JM, Moore W, Patterson A, Loranger B, Moore J, Neves C, Macdonald D, Tarkowska A, Sticco C, Hill E, Rossner M, Eliceiri KW, &amp;amp; Swedlow JR (2010). Metadata matters: access to image data in the real world. &lt;span style="font-style:italic;"&gt;The Journal of cell biology, 189&lt;/span&gt; (5), 777-82 PMID: &lt;a rev="review" href="http://www.ncbi.nlm.nih.gov/pubmed/20513764"&gt;20513764&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description><category>Planet SciPy</category><category>programming</category><category>Research Blogging</category><category>software</category><guid>https://ilovesymposia.com/2014/02/26/fiji-jython/</guid><pubDate>Tue, 25 Feb 2014 14:21:38 GMT</pubDate></item><item><title>OSX software watch: use Photosweeper to remove duplicates in your image collection</title><link>https://ilovesymposia.com/2013/10/15/osx-software-watch-use-photosweeper-to-remove-duplicates-in-your-image-collection/</link><dc:creator>Juan Nunez-Iglesias</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;It's no secret that the photo management problem is a huge mess. As new cameras, software, and online storage and sharing services come and go, our collections end up strewn all over the place, often in duplicate. This eats up precious storage space and makes finding that one photo an exercise in frustration.&lt;/p&gt;&lt;p&gt;Peter Nixey has an excellent post on the &lt;a href="http://peternixey.com/post/49928526270/dear-apple-lets-talk-about-photos"&gt;disappointing&lt;/a&gt; state of affairs (to put it kindly) and an excellent follow-up on how Dropbox could &lt;a href="http://peternixey.com/post/63634127289/how-dropbox-could-beat-apple-in-photos"&gt;fix it&lt;/a&gt;. You should definitely read those.&lt;/p&gt;&lt;p&gt;But, while Apple and/or Dropbox get their act together (I'm not holding my breath), you have to make sense of your photos in your Pictures folder, in your Dropbox Photos folder, in various other Dropbox shared folders, on your Desktop, in your Lightroom, Aperture, and iPhoto collections, and so on. A lot of these might be duplicated because, for example, you were just trying out Lightroom and didn't want to commit to it so you put your pics there but also in Aperture. And by you I mean I.&lt;/p&gt;&lt;p&gt;So, the first step to photo sanity is to get rid of these duplicates. Thankfully, there is an excellent OSX app called &lt;a href="http://photosweeper.com/photosweeper/index.html"&gt;Photosweeper&lt;/a&gt; made for just this purpose. I used it yesterday to clear 34GB of wasted space on my HDD. (I was too excited to take screenshots of the process, unfortunately!)&lt;/p&gt;&lt;p&gt;There's a lot to love about Photosweeper. First, it is happy to look at all the sources I mentioned above, and compare pics across them. Second, it lets you automatically define a priority for which version of a duplicate photo to save. In my case, I told it to keep iPhoto images first (since these are most likely to have ratings, captions, and so on), then Aperture, then whatever's on my HDD somewhere. If a duplicate was found &lt;em&gt;within&lt;/em&gt; iPhoto, it should keep the most recent one.&lt;/p&gt;&lt;p&gt;But, third, what makes Photosweeper truly useful: it won't do a thing without letting you review everything, and it offers a great reviewing interface. It places duplicates side-by-side, marking which photo it will keep and which it will trash. Best of all, this view shows everything you need to make sure you're not deleting a high-res original in favour of the downscaled version you emailed your family: filename, date, resolution, DPI, and file size. Click on each file and the full path (even within an iPhoto or Aperture library) becomes visible. This is in stark contrast to iPhoto's lame "hey, this is a duplicate file" dialog that shows you two downscaled versions of the images with &lt;em&gt;no further information.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;Once you bite the bullet, it does exactly the right thing with every duplicate: iPhoto duplicates get put in the iPhoto Trash, Lightroom duplicates get marked "Rejected" and put in a special "Trash (Photosweeper)" collection, and filesystem duplicates get moved to the OSX Trash. Lesser software might have moved all the iPhoto files to the OSX Trash, leaving the iPhoto library broken.&lt;/p&gt;&lt;p&gt;In all, I was really impressed with Photosweeper. 34GB is nothing to sniff at and getting rid of those duplicates is the first step to consolidating all my files. It does this in a very accountable, safe way. At no point did I get that sinking feeling of "there is no undo."&lt;/p&gt;&lt;p&gt;Finally, I should mention that Photosweeper also has a "photo similarity" mode that finds not only duplicates, but very similar series of photos. This is really good for when you snapped 15 pics of the same thing so that one might turn out ok. But I'm too much of a digital hoarder to take that step!&lt;/p&gt;&lt;p&gt;Photosweeper currently sells for $10 on the Mac App Store.&lt;/p&gt;&lt;/div&gt;</description><category>iphoto</category><category>osx</category><category>photo management</category><category>software</category><category>software review</category><guid>https://ilovesymposia.com/2013/10/15/osx-software-watch-use-photosweeper-to-remove-duplicates-in-your-image-collection/</guid><pubDate>Tue, 15 Oct 2013 12:59:53 GMT</pubDate></item><item><title>h5cat: quickly preview HDF5 file contents from the command-line</title><link>https://ilovesymposia.com/2012/05/09/h5cat-quickly-preview-hdf5-file-contents-from-the-command-line/</link><dc:creator>Juan Nunez-Iglesias</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;As a first attempt at writing actually useful blog posts, I'll publicise a small Python script I wrote to peek inside HDF5 files when &lt;a href="http://www.hdfgroup.org/hdf-java-html/hdfview/"&gt;HDFView&lt;/a&gt; is overkill. Sometimes you just want to know how many dimensions a stored array has, or its exact path within the HDF hierarchy. &lt;/p&gt;
&lt;p&gt;The “codebase” is currently tiny enough that it all fits below:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/usr/bin/env python&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nn"&gt;argparse&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;h5py&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt;

&lt;span class="n"&gt;arguments&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;argparse&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ArgumentParser&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;add_help&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;arggroup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;arguments&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_argument_group&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'HDF5 cat options'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;arggroup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'-g'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'--group'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;metavar&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'GROUP'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;help&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'Preview only path given by GROUP'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;arggroup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'-v'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'--verbose'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'store_true'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;help&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'Include array printout.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'__main__'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;parser&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;argparse&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ArgumentParser&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'Preview the contents of an HDF5 file'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;parents&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;arguments&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'fin'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nargs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'+'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;help&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'The input HDF5 files.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse_args&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;fin&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fin&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;'&amp;gt;&amp;gt;&amp;gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fin&lt;/span&gt;
        &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;h5py&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;File&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fin&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'r'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;group&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;groups&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;group&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;groups&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
            &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;visit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;groups&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;groups&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;   '&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;h5py&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;highlevel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dataset&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;'      shape: '&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;      type: '&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dtype&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;verbose&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
                    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;h5cat is &lt;a href="https://github.com/jni/h5cat"&gt;available&lt;/a&gt; on GitHub under an MIT license. Here's an example use case:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;$ h5cat -v -g vi single-channel-tr3-0-0.00.lzf.h5
&amp;gt;&amp;gt;&amp;gt; single-channel-tr3-0-0.00.lzf.h5

    vi
      shape:  &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;, &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; 
      type:  float64
&lt;span class="o"&gt;[[&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;.        &lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;.06224902&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;.23062383&lt;span class="o"&gt;]]&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;&lt;/p&gt;&lt;/div&gt;</description><category>Planet SciPy</category><category>programming</category><category>software</category><guid>https://ilovesymposia.com/2012/05/09/h5cat-quickly-preview-hdf5-file-contents-from-the-command-line/</guid><pubDate>Wed, 09 May 2012 06:29:05 GMT</pubDate></item><item><title>Microsoft Silverlight</title><link>https://ilovesymposia.com/2008/08/21/microsoft-silverlight/</link><dc:creator>Juan Nunez-Iglesias</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;I have to say that despite the &lt;a href="http://en.wikipedia.org/wiki/Silverlight"&gt;bad press&lt;/a&gt; Silverlight is getting at Wikipedia, I was pretty impressed using it in the &lt;a href="http://www.nbcolympics.com/"&gt;NBC Olympics&lt;/a&gt; site. Four live feeds at once? Yes please. This is what digital television was supposed to bring us, but never did. More important, fast forward, rewind and skip were stunningly responsive, which is more than I can say for Flash-based video. Finally, over my decent but not world-class DSL connection, video quality was fantastic, even at full-screen.&lt;/p&gt;
&lt;p&gt;Yeah, Silverlight uses proprietary software and eschews open standards. Like Facebook's closed platform and data policies, this bothers me. But like Facebook, Silverlight is simply ahead of the competition. Until the alternatives catch up, you can't blame consumers for sticking to the closed (but superior) platforms.&lt;/p&gt;&lt;/div&gt;</description><category>microsoft</category><category>olympics</category><category>open-source</category><category>proprietary software</category><category>silverlight</category><category>software</category><guid>https://ilovesymposia.com/2008/08/21/microsoft-silverlight/</guid><pubDate>Wed, 20 Aug 2008 15:32:25 GMT</pubDate></item></channel></rss>